{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mujaVlHHetaM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmFsyiqLe9DJ",
        "outputId": "258d0508-37eb-470e-f3e1-354491f2d0dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 6s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# loading the dataset\n",
        "from tensorflow.keras import datasets\n",
        "(train_img, train_lab), (test_img, test_lab) = datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "5pIOQqQ9fWqn",
        "outputId": "e7c4b0d6-1253-4bfa-b190-80aeed6097db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7820429262c0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#plotting an image from data\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_img[2005])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "xjkRLS-ogokR",
        "outputId": "f8b89ac2-1da2-4d97-d26b-1b8f3c9bdf2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 59,  62,  63],\n",
              "        [ 43,  46,  45],\n",
              "        [ 50,  48,  43],\n",
              "        ...,\n",
              "        [158, 132, 108],\n",
              "        [152, 125, 102],\n",
              "        [148, 124, 103]],\n",
              "\n",
              "       [[ 16,  20,  20],\n",
              "        [  0,   0,   0],\n",
              "        [ 18,   8,   0],\n",
              "        ...,\n",
              "        [123,  88,  55],\n",
              "        [119,  83,  50],\n",
              "        [122,  87,  57]],\n",
              "\n",
              "       [[ 25,  24,  21],\n",
              "        [ 16,   7,   0],\n",
              "        [ 49,  27,   8],\n",
              "        ...,\n",
              "        [118,  84,  50],\n",
              "        [120,  84,  50],\n",
              "        [109,  73,  42]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[208, 170,  96],\n",
              "        [201, 153,  34],\n",
              "        [198, 161,  26],\n",
              "        ...,\n",
              "        [160, 133,  70],\n",
              "        [ 56,  31,   7],\n",
              "        [ 53,  34,  20]],\n",
              "\n",
              "       [[180, 139,  96],\n",
              "        [173, 123,  42],\n",
              "        [186, 144,  30],\n",
              "        ...,\n",
              "        [184, 148,  94],\n",
              "        [ 97,  62,  34],\n",
              "        [ 83,  53,  34]],\n",
              "\n",
              "       [[177, 144, 116],\n",
              "        [168, 129,  94],\n",
              "        [179, 142,  87],\n",
              "        ...,\n",
              "        [216, 184, 140],\n",
              "        [151, 118,  84],\n",
              "        [123,  92,  72]]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-ad02e898-d47d-45ef-8f35-d23ec2c87fdd\" class=\"ndarray_repr\"><pre>ndarray (32, 32, 3) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,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\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[[ 59,  62,  63],\n",
              "        [ 43,  46,  45],\n",
              "        [ 50,  48,  43],\n",
              "        ...,\n",
              "        [158, 132, 108],\n",
              "        [152, 125, 102],\n",
              "        [148, 124, 103]],\n",
              "\n",
              "       [[ 16,  20,  20],\n",
              "        [  0,   0,   0],\n",
              "        [ 18,   8,   0],\n",
              "        ...,\n",
              "        [123,  88,  55],\n",
              "        [119,  83,  50],\n",
              "        [122,  87,  57]],\n",
              "\n",
              "       [[ 25,  24,  21],\n",
              "        [ 16,   7,   0],\n",
              "        [ 49,  27,   8],\n",
              "        ...,\n",
              "        [118,  84,  50],\n",
              "        [120,  84,  50],\n",
              "        [109,  73,  42]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[208, 170,  96],\n",
              "        [201, 153,  34],\n",
              "        [198, 161,  26],\n",
              "        ...,\n",
              "        [160, 133,  70],\n",
              "        [ 56,  31,   7],\n",
              "        [ 53,  34,  20]],\n",
              "\n",
              "       [[180, 139,  96],\n",
              "        [173, 123,  42],\n",
              "        [186, 144,  30],\n",
              "        ...,\n",
              "        [184, 148,  94],\n",
              "        [ 97,  62,  34],\n",
              "        [ 83,  53,  34]],\n",
              "\n",
              "       [[177, 144, 116],\n",
              "        [168, 129,  94],\n",
              "        [179, 142,  87],\n",
              "        ...,\n",
              "        [216, 184, 140],\n",
              "        [151, 118,  84],\n",
              "        [123,  92,  72]]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-ad02e898-d47d-45ef-8f35-d23ec2c87fdd button').onclick = (e) => {\n",
              "        document.querySelector('#id-ad02e898-d47d-45ef-8f35-d23ec2c87fdd').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-ad02e898-d47d-45ef-8f35-d23ec2c87fdd button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_img[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix46d3PBigyp",
        "outputId": "9a82af21-7824-4824-973a-95bff5a0085e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOC3HoC6flg8"
      },
      "outputs": [],
      "source": [
        "# normalizing the images\n",
        "train_img = train_img/255.0\n",
        "test_img = test_img/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-H65eq_f1-H",
        "outputId": "6cf0e910-7450-4c2a-bfed-80237e8d0f80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.10980392, 0.1372549 , 0.15294118],\n",
              "        [0.11764706, 0.13333333, 0.17254902],\n",
              "        [0.12941176, 0.17254902, 0.18431373],\n",
              "        ...,\n",
              "        [0.16862745, 0.21960784, 0.17647059],\n",
              "        [0.20392157, 0.25098039, 0.20784314],\n",
              "        [0.18039216, 0.22745098, 0.18431373]],\n",
              "\n",
              "       [[0.10588235, 0.11764706, 0.14901961],\n",
              "        [0.10588235, 0.10980392, 0.16078431],\n",
              "        [0.08235294, 0.12156863, 0.15294118],\n",
              "        ...,\n",
              "        [0.43921569, 0.53333333, 0.38039216],\n",
              "        [0.45882353, 0.54901961, 0.39607843],\n",
              "        [0.45098039, 0.54117647, 0.39215686]],\n",
              "\n",
              "       [[0.13333333, 0.14117647, 0.16470588],\n",
              "        [0.12941176, 0.12941176, 0.16862745],\n",
              "        [0.09411765, 0.11764706, 0.15686275],\n",
              "        ...,\n",
              "        [0.68627451, 0.81568627, 0.56078431],\n",
              "        [0.69411765, 0.81960784, 0.56470588],\n",
              "        [0.69019608, 0.81568627, 0.56078431]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.55686275, 0.69019608, 0.4627451 ],\n",
              "        [0.55686275, 0.69019608, 0.4627451 ],\n",
              "        [0.58823529, 0.72156863, 0.49803922],\n",
              "        ...,\n",
              "        [0.5254902 , 0.68627451, 0.46666667],\n",
              "        [0.50196078, 0.65882353, 0.43921569],\n",
              "        [0.5254902 , 0.68627451, 0.46666667]],\n",
              "\n",
              "       [[0.54901961, 0.69019608, 0.48627451],\n",
              "        [0.56862745, 0.70588235, 0.50588235],\n",
              "        [0.58823529, 0.72941176, 0.5254902 ],\n",
              "        ...,\n",
              "        [0.51372549, 0.66666667, 0.46666667],\n",
              "        [0.50980392, 0.66666667, 0.46666667],\n",
              "        [0.47843137, 0.63529412, 0.43529412]],\n",
              "\n",
              "       [[0.5254902 , 0.67058824, 0.48235294],\n",
              "        [0.53333333, 0.67058824, 0.48627451],\n",
              "        [0.53333333, 0.67058824, 0.48627451],\n",
              "        ...,\n",
              "        [0.41568627, 0.56470588, 0.39215686],\n",
              "        [0.40784314, 0.55686275, 0.38823529],\n",
              "        [0.39607843, 0.54901961, 0.37647059]]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_img[7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbtUgRQ1ikjE"
      },
      "outputs": [],
      "source": [
        "train_img = train_img.astype('float32')\n",
        "test_img = test_img.astype('float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJucyv90i70w"
      },
      "source": [
        "Model building"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
        "padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
        "padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
        "padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
        "padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
        "padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
        "padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "# compile model\n",
        "opt = SGD(lr=0.001, momentum=0.9)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XnqUta1opTe",
        "outputId": "109d47b7-c607-478c-8e86-c71bf121ec89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5j5A2bqpvZ-",
        "outputId": "54418e12-12dc-46f1-d9b7-47e63000c8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 32, 32, 32)        128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 16, 16, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 16, 16, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 32)          9248      \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 8, 8, 32)          128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 32)          9248      \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 8, 8, 32)          128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 32)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               65664     \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 128)               512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 115370 (450.66 KB)\n",
            "Trainable params: 114730 (448.16 KB)\n",
            "Non-trainable params: 640 (2.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "model6 = Sequential()\n",
        "model6.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "model6.add(BatchNormalization())\n",
        "model6.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model6.add(BatchNormalization())\n",
        "model6.add(MaxPooling2D((2, 2)))\n",
        "model6.add(Dropout(0.2))\n",
        "model6.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model6.add(BatchNormalization())\n",
        "model6.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model6.add(BatchNormalization())\n",
        "model6.add(MaxPooling2D((2, 2)))\n",
        "model6.add(Dropout(0.3))\n",
        "model6.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model6.add(BatchNormalization())\n",
        "model6.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model6.add(BatchNormalization())\n",
        "model6.add(MaxPooling2D((2, 2)))\n",
        "model6.add(Dropout(0.4))\n",
        "model6.add(Flatten())\n",
        "model6.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model6.add(BatchNormalization())\n",
        "model6.add(Dropout(0.5))\n",
        "model6.add(Dense(10, activation='softmax'))\n",
        "# compile model\n",
        "# opt = SGD(lr=0.001, momentum=0.9)\n",
        "model6.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True,rotation_range=20)\n",
        "it_train = datagen.flow(train_img, to_categorical(train_lab))\n",
        "steps = int(train_img.shape[0] / 64)\n",
        "history6=model6.fit_generator(it_train,epochs=80,steps_per_epoch=steps,validation_data=(test_img, to_categorical(test_lab)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuUg2Sy010XC",
        "outputId": "e8964f9b-7bb3-43f5-d70f-150f5764c4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-afbdcaa90091>:32: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history6=model6.fit_generator(it_train,epochs=80,steps_per_epoch=steps,validation_data=(test_img, to_categorical(test_lab)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "781/781 [==============================] - 43s 29ms/step - loss: 1.9631 - accuracy: 0.3361 - val_loss: 1.3923 - val_accuracy: 0.4963\n",
            "Epoch 2/80\n",
            "781/781 [==============================] - 21s 27ms/step - loss: 1.4666 - accuracy: 0.4694 - val_loss: 1.2459 - val_accuracy: 0.5483\n",
            "Epoch 3/80\n",
            "781/781 [==============================] - 21s 26ms/step - loss: 1.3187 - accuracy: 0.5270 - val_loss: 1.3855 - val_accuracy: 0.5272\n",
            "Epoch 4/80\n",
            "781/781 [==============================] - 21s 27ms/step - loss: 1.1978 - accuracy: 0.5721 - val_loss: 1.3004 - val_accuracy: 0.5828\n",
            "Epoch 5/80\n",
            "781/781 [==============================] - 21s 26ms/step - loss: 1.1190 - accuracy: 0.6089 - val_loss: 1.1146 - val_accuracy: 0.6125\n",
            "Epoch 6/80\n",
            "781/781 [==============================] - 19s 25ms/step - loss: 1.0597 - accuracy: 0.6295 - val_loss: 1.0118 - val_accuracy: 0.6551\n",
            "Epoch 7/80\n",
            "781/781 [==============================] - 21s 26ms/step - loss: 1.0132 - accuracy: 0.6477 - val_loss: 0.8998 - val_accuracy: 0.6915\n",
            "Epoch 8/80\n",
            "781/781 [==============================] - 20s 26ms/step - loss: 0.9641 - accuracy: 0.6655 - val_loss: 0.8826 - val_accuracy: 0.6971\n",
            "Epoch 9/80\n",
            "781/781 [==============================] - 20s 25ms/step - loss: 0.9282 - accuracy: 0.6799 - val_loss: 0.7546 - val_accuracy: 0.7424\n",
            "Epoch 10/80\n",
            "781/781 [==============================] - 22s 28ms/step - loss: 0.9019 - accuracy: 0.6905 - val_loss: 0.7941 - val_accuracy: 0.7318\n",
            "Epoch 11/80\n",
            "781/781 [==============================] - 20s 26ms/step - loss: 0.8671 - accuracy: 0.7050 - val_loss: 0.7748 - val_accuracy: 0.7387\n",
            "Epoch 12/80\n",
            "781/781 [==============================] - 20s 26ms/step - loss: 0.8555 - accuracy: 0.7069 - val_loss: 0.7517 - val_accuracy: 0.7464\n",
            "Epoch 13/80\n",
            "781/781 [==============================] - 21s 27ms/step - loss: 0.8193 - accuracy: 0.7165 - val_loss: 0.7263 - val_accuracy: 0.7563\n",
            "Epoch 14/80\n",
            "781/781 [==============================] - 21s 27ms/step - loss: 0.7996 - accuracy: 0.7266 - val_loss: 0.7179 - val_accuracy: 0.7585\n",
            "Epoch 15/80\n",
            "781/781 [==============================] - 21s 27ms/step - loss: 0.7947 - accuracy: 0.7303 - val_loss: 0.6318 - val_accuracy: 0.7840\n",
            "Epoch 16/80\n",
            "781/781 [==============================] - 21s 27ms/step - loss: 0.7815 - accuracy: 0.7328 - val_loss: 0.6165 - val_accuracy: 0.7875\n",
            "Epoch 17/80\n",
            "781/781 [==============================] - 21s 27ms/step - loss: 0.7596 - accuracy: 0.7384 - val_loss: 0.6691 - val_accuracy: 0.7728\n",
            "Epoch 18/80\n",
            "781/781 [==============================] - 21s 28ms/step - loss: 0.7490 - accuracy: 0.7440 - val_loss: 0.7009 - val_accuracy: 0.7629\n",
            "Epoch 19/80\n",
            "781/781 [==============================] - 21s 27ms/step - loss: 0.7313 - accuracy: 0.7497 - val_loss: 0.7485 - val_accuracy: 0.7562\n",
            "Epoch 20/80\n",
            "781/781 [==============================] - 21s 27ms/step - loss: 0.7209 - accuracy: 0.7544 - val_loss: 0.6266 - val_accuracy: 0.7877\n",
            "Epoch 21/80\n",
            "781/781 [==============================] - 20s 26ms/step - loss: 0.7106 - accuracy: 0.7573 - val_loss: 0.6528 - val_accuracy: 0.7793\n",
            "Epoch 22/80\n",
            "781/781 [==============================] - 21s 27ms/step - loss: 0.7000 - accuracy: 0.7650 - val_loss: 0.6014 - val_accuracy: 0.7944\n",
            "Epoch 23/80\n",
            "781/781 [==============================] - 21s 26ms/step - loss: 0.6948 - accuracy: 0.7640 - val_loss: 0.6113 - val_accuracy: 0.7963\n",
            "Epoch 24/80\n",
            "781/781 [==============================] - 21s 26ms/step - loss: 0.6986 - accuracy: 0.7620 - val_loss: 0.5915 - val_accuracy: 0.7968\n",
            "Epoch 25/80\n",
            "781/781 [==============================] - 20s 26ms/step - loss: 0.6874 - accuracy: 0.7672 - val_loss: 0.6019 - val_accuracy: 0.7958\n",
            "Epoch 26/80\n",
            "781/781 [==============================] - 20s 26ms/step - loss: 0.6727 - accuracy: 0.7704 - val_loss: 0.5891 - val_accuracy: 0.8006\n",
            "Epoch 27/80\n",
            "781/781 [==============================] - 21s 27ms/step - loss: 0.6696 - accuracy: 0.7745 - val_loss: 0.5923 - val_accuracy: 0.8009\n",
            "Epoch 28/80\n",
            "781/781 [==============================] - 21s 27ms/step - loss: 0.6608 - accuracy: 0.7740 - val_loss: 0.5655 - val_accuracy: 0.8089\n",
            "Epoch 29/80\n",
            "781/781 [==============================] - 20s 25ms/step - loss: 0.6526 - accuracy: 0.7789 - val_loss: 0.5462 - val_accuracy: 0.8125\n",
            "Epoch 30/80\n",
            "781/781 [==============================] - 21s 26ms/step - loss: 0.6461 - accuracy: 0.7826 - val_loss: 0.6195 - val_accuracy: 0.7954\n",
            "Epoch 31/80\n",
            "781/781 [==============================] - 20s 25ms/step - loss: 0.6422 - accuracy: 0.7814 - val_loss: 0.5465 - val_accuracy: 0.8126\n",
            "Epoch 32/80\n",
            "781/781 [==============================] - 21s 27ms/step - loss: 0.6346 - accuracy: 0.7863 - val_loss: 0.5206 - val_accuracy: 0.8223\n",
            "Epoch 33/80\n",
            "781/781 [==============================] - 20s 25ms/step - loss: 0.6265 - accuracy: 0.7886 - val_loss: 0.5253 - val_accuracy: 0.8246\n",
            "Epoch 34/80\n",
            "781/781 [==============================] - 20s 25ms/step - loss: 0.6239 - accuracy: 0.7892 - val_loss: 0.5606 - val_accuracy: 0.8146\n",
            "Epoch 35/80\n",
            "781/781 [==============================] - 20s 26ms/step - loss: 0.6128 - accuracy: 0.7917 - val_loss: 0.5095 - val_accuracy: 0.8272\n",
            "Epoch 36/80\n",
            "781/781 [==============================] - 20s 25ms/step - loss: 0.6292 - accuracy: 0.7914 - val_loss: 0.5019 - val_accuracy: 0.8318\n",
            "Epoch 37/80\n",
            "781/781 [==============================] - 20s 25ms/step - loss: 0.6070 - accuracy: 0.7939 - val_loss: 0.6038 - val_accuracy: 0.7969\n",
            "Epoch 38/80\n",
            "781/781 [==============================] - 22s 28ms/step - loss: 0.6038 - accuracy: 0.7952 - val_loss: 0.5915 - val_accuracy: 0.8070\n",
            "Epoch 39/80\n",
            "781/781 [==============================] - 19s 25ms/step - loss: 0.6049 - accuracy: 0.7981 - val_loss: 0.4704 - val_accuracy: 0.8378\n",
            "Epoch 40/80\n",
            "781/781 [==============================] - 20s 25ms/step - loss: 0.6069 - accuracy: 0.7953 - val_loss: 0.5146 - val_accuracy: 0.8274\n",
            "Epoch 41/80\n",
            "781/781 [==============================] - 19s 25ms/step - loss: 0.5817 - accuracy: 0.8021 - val_loss: 0.5611 - val_accuracy: 0.8171\n",
            "Epoch 42/80\n",
            "781/781 [==============================] - 20s 26ms/step - loss: 0.5987 - accuracy: 0.7964 - val_loss: 0.5610 - val_accuracy: 0.8157\n",
            "Epoch 43/80\n",
            "781/781 [==============================] - 20s 25ms/step - loss: 0.5788 - accuracy: 0.8045 - val_loss: 0.5304 - val_accuracy: 0.8234\n",
            "Epoch 44/80\n",
            "781/781 [==============================] - 19s 25ms/step - loss: 0.5853 - accuracy: 0.8035 - val_loss: 0.5149 - val_accuracy: 0.8263\n",
            "Epoch 45/80\n",
            "781/781 [==============================] - 20s 26ms/step - loss: 0.5789 - accuracy: 0.8041 - val_loss: 0.5494 - val_accuracy: 0.8178\n",
            "Epoch 46/80\n",
            "781/781 [==============================] - 20s 25ms/step - loss: 0.5689 - accuracy: 0.8085 - val_loss: 0.5006 - val_accuracy: 0.8332\n",
            "Epoch 47/80\n",
            "781/781 [==============================] - 20s 26ms/step - loss: 0.5646 - accuracy: 0.8061 - val_loss: 0.6080 - val_accuracy: 0.8016\n",
            "Epoch 48/80\n",
            "781/781 [==============================] - 20s 26ms/step - loss: 0.5719 - accuracy: 0.8080 - val_loss: 0.4687 - val_accuracy: 0.8444\n",
            "Epoch 49/80\n",
            "781/781 [==============================] - 20s 26ms/step - loss: 0.5655 - accuracy: 0.8104 - val_loss: 0.5617 - val_accuracy: 0.8129\n",
            "Epoch 50/80\n",
            "781/781 [==============================] - 21s 26ms/step - loss: 0.5727 - accuracy: 0.8064 - val_loss: 0.4934 - val_accuracy: 0.8354\n",
            "Epoch 51/80\n",
            "781/781 [==============================] - 20s 25ms/step - loss: 0.5606 - accuracy: 0.8102 - val_loss: 0.5308 - val_accuracy: 0.8256\n",
            "Epoch 52/80\n",
            "781/781 [==============================] - 20s 25ms/step - loss: 0.5654 - accuracy: 0.8096 - val_loss: 0.4585 - val_accuracy: 0.8471\n",
            "Epoch 53/80\n",
            "781/781 [==============================] - 20s 26ms/step - loss: 0.5560 - accuracy: 0.8124 - val_loss: 0.4929 - val_accuracy: 0.8385\n",
            "Epoch 54/80\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5399 - accuracy: 0.8178 - val_loss: 0.4979 - val_accuracy: 0.8363\n",
            "Epoch 55/80\n",
            "781/781 [==============================] - 20s 25ms/step - loss: 0.5540 - accuracy: 0.8141 - val_loss: 0.5836 - val_accuracy: 0.8129\n",
            "Epoch 56/80\n",
            "781/781 [==============================] - 20s 25ms/step - loss: 0.5509 - accuracy: 0.8138 - val_loss: 0.5055 - val_accuracy: 0.8335\n",
            "Epoch 57/80\n",
            "781/781 [==============================] - 20s 26ms/step - loss: 0.5476 - accuracy: 0.8163 - val_loss: 0.4673 - val_accuracy: 0.8465\n",
            "Epoch 58/80\n",
            "781/781 [==============================] - 19s 25ms/step - loss: 0.5370 - accuracy: 0.8197 - val_loss: 0.4283 - val_accuracy: 0.8541\n",
            "Epoch 59/80\n",
            "781/781 [==============================] - 21s 28ms/step - loss: 0.5422 - accuracy: 0.8183 - val_loss: 0.5070 - val_accuracy: 0.8309\n",
            "Epoch 60/80\n",
            "781/781 [==============================] - 22s 28ms/step - loss: 0.5399 - accuracy: 0.8181 - val_loss: 0.4668 - val_accuracy: 0.8456\n",
            "Epoch 61/80\n",
            "781/781 [==============================] - 20s 25ms/step - loss: 0.5384 - accuracy: 0.8187 - val_loss: 0.4816 - val_accuracy: 0.8384\n",
            "Epoch 62/80\n",
            "781/781 [==============================] - 21s 26ms/step - loss: 0.5310 - accuracy: 0.8201 - val_loss: 0.4865 - val_accuracy: 0.8358\n",
            "Epoch 63/80\n",
            "781/781 [==============================] - 20s 25ms/step - loss: 0.5293 - accuracy: 0.8229 - val_loss: 0.4822 - val_accuracy: 0.8383\n",
            "Epoch 64/80\n",
            "781/781 [==============================] - 21s 26ms/step - loss: 0.5210 - accuracy: 0.8237 - val_loss: 0.4421 - val_accuracy: 0.8523\n",
            "Epoch 65/80\n",
            "781/781 [==============================] - 20s 26ms/step - loss: 0.5217 - accuracy: 0.8247 - val_loss: 0.5288 - val_accuracy: 0.8228\n",
            "Epoch 66/80\n",
            "781/781 [==============================] - 20s 26ms/step - loss: 0.5277 - accuracy: 0.8208 - val_loss: 0.4715 - val_accuracy: 0.8451\n",
            "Epoch 67/80\n",
            "781/781 [==============================] - 21s 26ms/step - loss: 0.5316 - accuracy: 0.8194 - val_loss: 0.4821 - val_accuracy: 0.8400\n",
            "Epoch 68/80\n",
            "781/781 [==============================] - 21s 27ms/step - loss: 0.5200 - accuracy: 0.8261 - val_loss: 0.4392 - val_accuracy: 0.8553\n",
            "Epoch 69/80\n",
            "781/781 [==============================] - 21s 26ms/step - loss: 0.5181 - accuracy: 0.8234 - val_loss: 0.4295 - val_accuracy: 0.8574\n",
            "Epoch 70/80\n",
            "781/781 [==============================] - 19s 25ms/step - loss: 0.5111 - accuracy: 0.8303 - val_loss: 0.4815 - val_accuracy: 0.8352\n",
            "Epoch 71/80\n",
            "781/781 [==============================] - 21s 27ms/step - loss: 0.5165 - accuracy: 0.8247 - val_loss: 0.4905 - val_accuracy: 0.8365\n",
            "Epoch 72/80\n",
            "781/781 [==============================] - 20s 25ms/step - loss: 0.5195 - accuracy: 0.8272 - val_loss: 0.5261 - val_accuracy: 0.8330\n",
            "Epoch 73/80\n",
            "781/781 [==============================] - 19s 25ms/step - loss: 0.5061 - accuracy: 0.8303 - val_loss: 0.4314 - val_accuracy: 0.8539\n",
            "Epoch 74/80\n",
            "781/781 [==============================] - 21s 26ms/step - loss: 0.5032 - accuracy: 0.8297 - val_loss: 0.4503 - val_accuracy: 0.8495\n",
            "Epoch 75/80\n",
            "781/781 [==============================] - 21s 27ms/step - loss: 0.5010 - accuracy: 0.8315 - val_loss: 0.4011 - val_accuracy: 0.8625\n",
            "Epoch 76/80\n",
            "781/781 [==============================] - 19s 25ms/step - loss: 0.5104 - accuracy: 0.8263 - val_loss: 0.4403 - val_accuracy: 0.8548\n",
            "Epoch 77/80\n",
            "781/781 [==============================] - 21s 27ms/step - loss: 0.4997 - accuracy: 0.8319 - val_loss: 0.4259 - val_accuracy: 0.8605\n",
            "Epoch 78/80\n",
            "781/781 [==============================] - 23s 29ms/step - loss: 0.5024 - accuracy: 0.8308 - val_loss: 0.4448 - val_accuracy: 0.8545\n",
            "Epoch 79/80\n",
            "781/781 [==============================] - 19s 25ms/step - loss: 0.5008 - accuracy: 0.8308 - val_loss: 0.4501 - val_accuracy: 0.8510\n",
            "Epoch 80/80\n",
            "781/781 [==============================] - 21s 27ms/step - loss: 0.5007 - accuracy: 0.8296 - val_loss: 0.5206 - val_accuracy: 0.8297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AupCOCyWqx-l"
      },
      "source": [
        "Intermediate layer model, before data is fed into the xgboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vkO_hrSQRXE",
        "outputId": "a4d8bcb7-5efa-4c52-a96d-dcf65208b030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 32, 32, 32)        128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 8, 8, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 8, 8, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               262272    \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 128)               512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 552874 (2.11 MB)\n",
            "Trainable params: 551722 (2.10 MB)\n",
            "Non-trainable params: 1152 (4.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model6.layers[18]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGFqLhbrWuSF",
        "outputId": "98f94be2-5aa2-431b-efd0-7d546ce7dd69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.layers.reshaping.flatten.Flatten at 0x781fec3c6140>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmmC_9l3pV0-"
      },
      "outputs": [],
      "source": [
        "flatten_model = tf.keras.Model(inputs = model6.inputs, outputs = model6.layers[18].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsLIC4gYqtCx",
        "outputId": "9f87384f-e9d3-4e2d-8427-c35e58c0657b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_input (InputLayer)   [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 32, 32, 32)        128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 8, 8, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 8, 8, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 288800 (1.10 MB)\n",
            "Trainable params: 287904 (1.10 MB)\n",
            "Non-trainable params: 896 (3.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "flatten_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1akOPtIx7Tc"
      },
      "source": [
        "Values obtained from the flatten layer( Dataset for other models )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yA7rWHZq24q",
        "outputId": "0c3068ce-229c-4ad9-d8b0-74cffd00d8e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 3s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "features_train = flatten_model.predict(train_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxVMhGf2sraS",
        "outputId": "3850ea8b-1f92-49c5-e709-dd915abdf80c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.5345629 , -0.6036698 ,  1.0652056 , ..., -0.20596674,\n",
              "       -0.4728356 , -0.75781465], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "features_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_train[shape]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "3ttLEMWYA0nE",
        "outputId": "5486a61c-fc96-45d8-a8a5-def14af2503a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'shape' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c27e90365020>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'shape' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa2zlPpesYYh",
        "outputId": "62218e6f-1ab5-48ce-daff-4e67cb0a76d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "features_test = flatten_model.predict(test_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBI3cTW6tWAT",
        "outputId": "751cd6fd-1af5-4941-e7df-cd8de3d125a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2048)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "features_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL7WGOsnrLLj",
        "outputId": "c0e207b1-7313-4f18-8b5e-f14103d26310"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 2048)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "features_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6TA1cGktZpj",
        "outputId": "6ad97183-5fa2-4e8f-ad01-9477e64ceec7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "type(features_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KK8QBUX3Q_m5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jFwVZurQ6Gp"
      },
      "outputs": [],
      "source": [
        "dataset = pd.DataFrame(features_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "q7kzqjGJyOPO",
        "outputId": "94c36759-b014-412e-e12d-c0ca7c266b07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0         1         2         3         4         5         6     \\\n",
              "0 -0.684263 -0.706851  0.682849  0.068414 -0.461987 -0.510734 -0.064524   \n",
              "1 -0.684263 -0.706851 -0.698777 -0.949980  4.430528  1.221830  0.069785   \n",
              "2 -0.684263 -0.363818 -0.698777 -0.949980  0.442858 -0.510734 -0.829178   \n",
              "3 -0.684263 -0.706851 -0.698777  2.337670 -0.686239 -0.510734 -0.791893   \n",
              "4 -0.684263 -0.706851 -0.698777  1.143971  0.310926 -0.510734 -0.342076   \n",
              "\n",
              "       7         8         9     ...     2038      2039      2040       2041  \\\n",
              "0 -0.707391  0.011639 -0.490601  ... -0.85852 -0.771150  0.661550   0.638916   \n",
              "1 -0.950473 -0.629810 -0.490601  ... -0.85852 -0.771150 -0.771627  12.357662   \n",
              "2 -0.950473 -0.629810 -0.490601  ... -0.85852 -0.136581  1.886167  -0.686965   \n",
              "3 -0.490045 -0.629810 -0.490601  ... -0.85852 -0.771150  0.974180  -0.686965   \n",
              "4 -0.950473 -0.629810 -0.490601  ... -0.85852  1.266940  1.124244   7.560091   \n",
              "\n",
              "       2042      2043      2044      2045      2046      2047  \n",
              "0 -0.981759 -0.413278 -0.187591 -0.667974  0.550370  2.156868  \n",
              "1 -0.981759  0.625245 -0.914341 -0.667974 -0.534845 -0.791722  \n",
              "2 -0.981759 -0.871450 -0.428460 -0.667974 -0.534845 -0.791722  \n",
              "3 -0.981759 -0.871450  1.987253 -0.667974 -0.534845 -0.748093  \n",
              "4 -0.981759  0.899928 -0.914341 -0.667974 -0.534845 -0.791722  \n",
              "\n",
              "[5 rows x 2048 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98cbc240-460d-4597-9478-9a532d8508cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>2038</th>\n",
              "      <th>2039</th>\n",
              "      <th>2040</th>\n",
              "      <th>2041</th>\n",
              "      <th>2042</th>\n",
              "      <th>2043</th>\n",
              "      <th>2044</th>\n",
              "      <th>2045</th>\n",
              "      <th>2046</th>\n",
              "      <th>2047</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.684263</td>\n",
              "      <td>-0.706851</td>\n",
              "      <td>0.682849</td>\n",
              "      <td>0.068414</td>\n",
              "      <td>-0.461987</td>\n",
              "      <td>-0.510734</td>\n",
              "      <td>-0.064524</td>\n",
              "      <td>-0.707391</td>\n",
              "      <td>0.011639</td>\n",
              "      <td>-0.490601</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.85852</td>\n",
              "      <td>-0.771150</td>\n",
              "      <td>0.661550</td>\n",
              "      <td>0.638916</td>\n",
              "      <td>-0.981759</td>\n",
              "      <td>-0.413278</td>\n",
              "      <td>-0.187591</td>\n",
              "      <td>-0.667974</td>\n",
              "      <td>0.550370</td>\n",
              "      <td>2.156868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.684263</td>\n",
              "      <td>-0.706851</td>\n",
              "      <td>-0.698777</td>\n",
              "      <td>-0.949980</td>\n",
              "      <td>4.430528</td>\n",
              "      <td>1.221830</td>\n",
              "      <td>0.069785</td>\n",
              "      <td>-0.950473</td>\n",
              "      <td>-0.629810</td>\n",
              "      <td>-0.490601</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.85852</td>\n",
              "      <td>-0.771150</td>\n",
              "      <td>-0.771627</td>\n",
              "      <td>12.357662</td>\n",
              "      <td>-0.981759</td>\n",
              "      <td>0.625245</td>\n",
              "      <td>-0.914341</td>\n",
              "      <td>-0.667974</td>\n",
              "      <td>-0.534845</td>\n",
              "      <td>-0.791722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.684263</td>\n",
              "      <td>-0.363818</td>\n",
              "      <td>-0.698777</td>\n",
              "      <td>-0.949980</td>\n",
              "      <td>0.442858</td>\n",
              "      <td>-0.510734</td>\n",
              "      <td>-0.829178</td>\n",
              "      <td>-0.950473</td>\n",
              "      <td>-0.629810</td>\n",
              "      <td>-0.490601</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.85852</td>\n",
              "      <td>-0.136581</td>\n",
              "      <td>1.886167</td>\n",
              "      <td>-0.686965</td>\n",
              "      <td>-0.981759</td>\n",
              "      <td>-0.871450</td>\n",
              "      <td>-0.428460</td>\n",
              "      <td>-0.667974</td>\n",
              "      <td>-0.534845</td>\n",
              "      <td>-0.791722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.684263</td>\n",
              "      <td>-0.706851</td>\n",
              "      <td>-0.698777</td>\n",
              "      <td>2.337670</td>\n",
              "      <td>-0.686239</td>\n",
              "      <td>-0.510734</td>\n",
              "      <td>-0.791893</td>\n",
              "      <td>-0.490045</td>\n",
              "      <td>-0.629810</td>\n",
              "      <td>-0.490601</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.85852</td>\n",
              "      <td>-0.771150</td>\n",
              "      <td>0.974180</td>\n",
              "      <td>-0.686965</td>\n",
              "      <td>-0.981759</td>\n",
              "      <td>-0.871450</td>\n",
              "      <td>1.987253</td>\n",
              "      <td>-0.667974</td>\n",
              "      <td>-0.534845</td>\n",
              "      <td>-0.748093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.684263</td>\n",
              "      <td>-0.706851</td>\n",
              "      <td>-0.698777</td>\n",
              "      <td>1.143971</td>\n",
              "      <td>0.310926</td>\n",
              "      <td>-0.510734</td>\n",
              "      <td>-0.342076</td>\n",
              "      <td>-0.950473</td>\n",
              "      <td>-0.629810</td>\n",
              "      <td>-0.490601</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.85852</td>\n",
              "      <td>1.266940</td>\n",
              "      <td>1.124244</td>\n",
              "      <td>7.560091</td>\n",
              "      <td>-0.981759</td>\n",
              "      <td>0.899928</td>\n",
              "      <td>-0.914341</td>\n",
              "      <td>-0.667974</td>\n",
              "      <td>-0.534845</td>\n",
              "      <td>-0.791722</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  2048 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98cbc240-460d-4597-9478-9a532d8508cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-98cbc240-460d-4597-9478-9a532d8508cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-98cbc240-460d-4597-9478-9a532d8508cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zNSFZNaRHMH"
      },
      "outputs": [],
      "source": [
        "dataset['train_label'] = train_lab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHrH8piwyYYi"
      },
      "outputs": [],
      "source": [
        "lab_train = dataset['train_label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgDBAxbkyRR6",
        "outputId": "661c2fde-dd5c-414f-a4f6-8525e51c9c7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       ...,\n",
              "       [9],\n",
              "       [1],\n",
              "       [1]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "train_lab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "zfmDh648RQkU",
        "outputId": "78544ccf-a07d-4634-97ac-1833bf3ed73e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0 -0.684263 -0.706851  0.682849  0.068414 -0.461987 -0.510734 -0.064524   \n",
              "1 -0.684263 -0.706851 -0.698777 -0.949980  4.430528  1.221830  0.069785   \n",
              "2 -0.684263 -0.363818 -0.698777 -0.949980  0.442858 -0.510734 -0.829178   \n",
              "3 -0.684263 -0.706851 -0.698777  2.337670 -0.686239 -0.510734 -0.791893   \n",
              "4 -0.684263 -0.706851 -0.698777  1.143971  0.310926 -0.510734 -0.342076   \n",
              "\n",
              "          7         8         9  ...      2039      2040       2041      2042  \\\n",
              "0 -0.707391  0.011639 -0.490601  ... -0.771150  0.661550   0.638916 -0.981759   \n",
              "1 -0.950473 -0.629810 -0.490601  ... -0.771150 -0.771627  12.357662 -0.981759   \n",
              "2 -0.950473 -0.629810 -0.490601  ... -0.136581  1.886167  -0.686965 -0.981759   \n",
              "3 -0.490045 -0.629810 -0.490601  ... -0.771150  0.974180  -0.686965 -0.981759   \n",
              "4 -0.950473 -0.629810 -0.490601  ...  1.266940  1.124244   7.560091 -0.981759   \n",
              "\n",
              "       2043      2044      2045      2046      2047  train_label  \n",
              "0 -0.413278 -0.187591 -0.667974  0.550370  2.156868            6  \n",
              "1  0.625245 -0.914341 -0.667974 -0.534845 -0.791722            9  \n",
              "2 -0.871450 -0.428460 -0.667974 -0.534845 -0.791722            9  \n",
              "3 -0.871450  1.987253 -0.667974 -0.534845 -0.748093            4  \n",
              "4  0.899928 -0.914341 -0.667974 -0.534845 -0.791722            1  \n",
              "\n",
              "[5 rows x 2049 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a717ce6-321f-4771-9384-b7a4f42751bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>2039</th>\n",
              "      <th>2040</th>\n",
              "      <th>2041</th>\n",
              "      <th>2042</th>\n",
              "      <th>2043</th>\n",
              "      <th>2044</th>\n",
              "      <th>2045</th>\n",
              "      <th>2046</th>\n",
              "      <th>2047</th>\n",
              "      <th>train_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.684263</td>\n",
              "      <td>-0.706851</td>\n",
              "      <td>0.682849</td>\n",
              "      <td>0.068414</td>\n",
              "      <td>-0.461987</td>\n",
              "      <td>-0.510734</td>\n",
              "      <td>-0.064524</td>\n",
              "      <td>-0.707391</td>\n",
              "      <td>0.011639</td>\n",
              "      <td>-0.490601</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.771150</td>\n",
              "      <td>0.661550</td>\n",
              "      <td>0.638916</td>\n",
              "      <td>-0.981759</td>\n",
              "      <td>-0.413278</td>\n",
              "      <td>-0.187591</td>\n",
              "      <td>-0.667974</td>\n",
              "      <td>0.550370</td>\n",
              "      <td>2.156868</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.684263</td>\n",
              "      <td>-0.706851</td>\n",
              "      <td>-0.698777</td>\n",
              "      <td>-0.949980</td>\n",
              "      <td>4.430528</td>\n",
              "      <td>1.221830</td>\n",
              "      <td>0.069785</td>\n",
              "      <td>-0.950473</td>\n",
              "      <td>-0.629810</td>\n",
              "      <td>-0.490601</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.771150</td>\n",
              "      <td>-0.771627</td>\n",
              "      <td>12.357662</td>\n",
              "      <td>-0.981759</td>\n",
              "      <td>0.625245</td>\n",
              "      <td>-0.914341</td>\n",
              "      <td>-0.667974</td>\n",
              "      <td>-0.534845</td>\n",
              "      <td>-0.791722</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.684263</td>\n",
              "      <td>-0.363818</td>\n",
              "      <td>-0.698777</td>\n",
              "      <td>-0.949980</td>\n",
              "      <td>0.442858</td>\n",
              "      <td>-0.510734</td>\n",
              "      <td>-0.829178</td>\n",
              "      <td>-0.950473</td>\n",
              "      <td>-0.629810</td>\n",
              "      <td>-0.490601</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.136581</td>\n",
              "      <td>1.886167</td>\n",
              "      <td>-0.686965</td>\n",
              "      <td>-0.981759</td>\n",
              "      <td>-0.871450</td>\n",
              "      <td>-0.428460</td>\n",
              "      <td>-0.667974</td>\n",
              "      <td>-0.534845</td>\n",
              "      <td>-0.791722</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.684263</td>\n",
              "      <td>-0.706851</td>\n",
              "      <td>-0.698777</td>\n",
              "      <td>2.337670</td>\n",
              "      <td>-0.686239</td>\n",
              "      <td>-0.510734</td>\n",
              "      <td>-0.791893</td>\n",
              "      <td>-0.490045</td>\n",
              "      <td>-0.629810</td>\n",
              "      <td>-0.490601</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.771150</td>\n",
              "      <td>0.974180</td>\n",
              "      <td>-0.686965</td>\n",
              "      <td>-0.981759</td>\n",
              "      <td>-0.871450</td>\n",
              "      <td>1.987253</td>\n",
              "      <td>-0.667974</td>\n",
              "      <td>-0.534845</td>\n",
              "      <td>-0.748093</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.684263</td>\n",
              "      <td>-0.706851</td>\n",
              "      <td>-0.698777</td>\n",
              "      <td>1.143971</td>\n",
              "      <td>0.310926</td>\n",
              "      <td>-0.510734</td>\n",
              "      <td>-0.342076</td>\n",
              "      <td>-0.950473</td>\n",
              "      <td>-0.629810</td>\n",
              "      <td>-0.490601</td>\n",
              "      <td>...</td>\n",
              "      <td>1.266940</td>\n",
              "      <td>1.124244</td>\n",
              "      <td>7.560091</td>\n",
              "      <td>-0.981759</td>\n",
              "      <td>0.899928</td>\n",
              "      <td>-0.914341</td>\n",
              "      <td>-0.667974</td>\n",
              "      <td>-0.534845</td>\n",
              "      <td>-0.791722</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  2049 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a717ce6-321f-4771-9384-b7a4f42751bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a717ce6-321f-4771-9384-b7a4f42751bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a717ce6-321f-4771-9384-b7a4f42751bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLk6cfVxRYhd",
        "outputId": "d7df66f0-771d-48fc-d00b-89dd7835ae6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2049)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smv1LaOJynHd"
      },
      "source": [
        "Below - 'f' stands for feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V193aCvBRg91"
      },
      "outputs": [],
      "source": [
        "train_f_labels = dataset['train_label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eOofl6OSr_n"
      },
      "outputs": [],
      "source": [
        "train_f_labels = train_f_labels.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypLguHJLyuYv"
      },
      "source": [
        "Train dataset which will get fed into models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tv2X2jgbSkxs"
      },
      "outputs": [],
      "source": [
        "train_f = dataset.drop(labels = ['train_label'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92FY_Ln3TQR6"
      },
      "outputs": [],
      "source": [
        "train_f = train_f.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBgcvM3wTUeo",
        "outputId": "327e2d2f-59f8-4238-cf4d-455f7e867685"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.68426263, -0.7068512 ,  0.6828489 , ..., -0.6679738 ,\n",
              "         0.5503702 ,  2.1568685 ],\n",
              "       [-0.68426263, -0.7068512 , -0.69877666, ..., -0.6679738 ,\n",
              "        -0.5348451 , -0.79172206],\n",
              "       [-0.68426263, -0.36381823, -0.69877666, ..., -0.6679738 ,\n",
              "        -0.5348451 , -0.79172206],\n",
              "       ...,\n",
              "       [-0.68426263,  1.5366741 , -0.69877666, ...,  0.6565158 ,\n",
              "        -0.5348451 , -0.79172206],\n",
              "       [-0.68426263,  0.9428658 , -0.69877666, ..., -0.6679738 ,\n",
              "         2.9562042 ,  0.4426829 ],\n",
              "       [-0.68426263, -0.7068512 , -0.69877666, ...,  4.4974275 ,\n",
              "        -0.2847044 , -0.79172206]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "train_f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFIFTod9tfru"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AALETPJbtnmz"
      },
      "outputs": [],
      "source": [
        "xg = xgb.XGBClassifier(objective = 'multi:softmax', num_class=10, n_estimators = 100, max_depth = 4, learning_rate = 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKan5f8r0Lr-"
      },
      "source": [
        "# Now, Train features and labels : train_f, train_f_labels\n",
        "##    Test features and labels : test_f, test_f_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "Pc6JCvQb42qK",
        "outputId": "727b778d-2c87-4667-8381-5f1009b641a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_class=10,\n",
              "              num_parallel_tree=None, objective='multi:softmax', ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_class=10,\n",
              "              num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_class=10,\n",
              "              num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "xg.fit(train_f, train_f_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPXqmpR1axEG",
        "outputId": "492f2d1c-caf4-4eba-9a1d-11ccf44e97bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 9, 9, ..., 9, 1, 1], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "train_f_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9BDjB9EzG52"
      },
      "source": [
        "Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqW1uty0ZQvD"
      },
      "outputs": [],
      "source": [
        "test_f = pd.DataFrame(features_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "6KCxJdxgZ7De",
        "outputId": "c90e21e4-5b16-4aab-9e8f-eaec7c07fb60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0         1         2         3         4         5         6     \\\n",
              "0 -0.419521 -0.706851  1.857408 -0.949980  1.910852  1.039224 -0.829178   \n",
              "1 -0.684263  2.880928 -0.698777 -0.204218  1.812628 -0.510734 -0.829178   \n",
              "2 -0.607797  1.929573 -0.698777  0.867342  1.080791 -0.283759 -0.829178   \n",
              "3 -0.494716  0.348679 -0.514203  1.013379  1.515830 -0.510734 -0.829178   \n",
              "4 -0.684263  0.595475 -0.698777  0.084498  2.959814 -0.510734 -0.829178   \n",
              "5 -0.684263 -0.706851 -0.698777  1.511019 -0.210173 -0.510734  0.467025   \n",
              "6 -0.684263 -0.706851 -0.698777 -0.312307 -0.771167 -0.510734  1.055458   \n",
              "7 -0.684263  0.506747  3.384523 -0.832172  0.010346  0.925514 -0.829178   \n",
              "8  1.529879 -0.706851  1.716731 -0.622971 -0.668859 -0.227116 -0.829178   \n",
              "9 -0.684263 -0.706851 -0.698777 -0.556059  1.354789 -0.132860 -0.829178   \n",
              "\n",
              "       7         8         9     ...     2038      2039      2040      2041  \\\n",
              "0  0.076660 -0.629810  0.503043  ... -0.85852  1.094330 -0.771627 -0.686965   \n",
              "1 -0.950473 -0.629810 -0.490601  ... -0.85852  8.752217  5.251047 -0.686965   \n",
              "2 -0.950473 -0.629810 -0.490601  ... -0.85852 -0.402539  0.635942  4.067854   \n",
              "3  0.273282 -0.629810 -0.490601  ... -0.85852  0.927870 -0.320838 -0.686965   \n",
              "4 -0.950473 -0.629810 -0.490601  ... -0.85852 -0.771150  0.829837 -0.254614   \n",
              "5 -0.258887  1.199516 -0.157384  ... -0.85852  0.983767  2.165945  1.594887   \n",
              "6 -0.569919 -0.629810 -0.490601  ... -0.85852 -0.458171 -0.771627  6.847553   \n",
              "7  0.181350 -0.629810 -0.490601  ... -0.85852  0.894464  3.494938 -0.686965   \n",
              "8 -0.950473 -0.629810 -0.490601  ... -0.85852 -0.771150 -0.030263 -0.686965   \n",
              "9 -0.950473 -0.629810 -0.490601  ... -0.85852  0.405067 -0.771627  2.012566   \n",
              "\n",
              "       2042      2043      2044      2045      2046      2047  \n",
              "0 -0.443598 -0.731515 -0.914341  0.522302 -0.534845  1.567848  \n",
              "1 -0.981759 -0.871450 -0.914341 -0.667974 -0.534845 -0.791722  \n",
              "2 -0.688163 -0.871450 -0.914341 -0.667974 -0.386116  1.173936  \n",
              "3  1.308509 -0.871450 -0.914341  0.922712 -0.534845  0.233945  \n",
              "4 -0.981759 -0.871450  2.534453 -0.667974 -0.534845  3.130798  \n",
              "5 -0.981759 -0.871450 -0.914341 -0.667974 -0.534845 -0.791722  \n",
              "6 -0.422549  0.932286 -0.914341 -0.667974 -0.135992 -0.791722  \n",
              "7 -0.981759 -0.871450 -0.017789 -0.039492 -0.534845  1.515929  \n",
              "8 -0.981759 -0.871450  1.668778 -0.667974 -0.534845  0.616387  \n",
              "9 -0.981759  0.581057 -0.914341 -0.667974  2.621031  0.713698  \n",
              "\n",
              "[10 rows x 2048 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b50819c0-06d6-4d0a-82c9-765b442ad053\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>2038</th>\n",
              "      <th>2039</th>\n",
              "      <th>2040</th>\n",
              "      <th>2041</th>\n",
              "      <th>2042</th>\n",
              "      <th>2043</th>\n",
              "      <th>2044</th>\n",
              "      <th>2045</th>\n",
              "      <th>2046</th>\n",
              "      <th>2047</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.419521</td>\n",
              "      <td>-0.706851</td>\n",
              "      <td>1.857408</td>\n",
              "      <td>-0.949980</td>\n",
              "      <td>1.910852</td>\n",
              "      <td>1.039224</td>\n",
              "      <td>-0.829178</td>\n",
              "      <td>0.076660</td>\n",
              "      <td>-0.629810</td>\n",
              "      <td>0.503043</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.85852</td>\n",
              "      <td>1.094330</td>\n",
              "      <td>-0.771627</td>\n",
              "      <td>-0.686965</td>\n",
              "      <td>-0.443598</td>\n",
              "      <td>-0.731515</td>\n",
              "      <td>-0.914341</td>\n",
              "      <td>0.522302</td>\n",
              "      <td>-0.534845</td>\n",
              "      <td>1.567848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.684263</td>\n",
              "      <td>2.880928</td>\n",
              "      <td>-0.698777</td>\n",
              "      <td>-0.204218</td>\n",
              "      <td>1.812628</td>\n",
              "      <td>-0.510734</td>\n",
              "      <td>-0.829178</td>\n",
              "      <td>-0.950473</td>\n",
              "      <td>-0.629810</td>\n",
              "      <td>-0.490601</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.85852</td>\n",
              "      <td>8.752217</td>\n",
              "      <td>5.251047</td>\n",
              "      <td>-0.686965</td>\n",
              "      <td>-0.981759</td>\n",
              "      <td>-0.871450</td>\n",
              "      <td>-0.914341</td>\n",
              "      <td>-0.667974</td>\n",
              "      <td>-0.534845</td>\n",
              "      <td>-0.791722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.607797</td>\n",
              "      <td>1.929573</td>\n",
              "      <td>-0.698777</td>\n",
              "      <td>0.867342</td>\n",
              "      <td>1.080791</td>\n",
              "      <td>-0.283759</td>\n",
              "      <td>-0.829178</td>\n",
              "      <td>-0.950473</td>\n",
              "      <td>-0.629810</td>\n",
              "      <td>-0.490601</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.85852</td>\n",
              "      <td>-0.402539</td>\n",
              "      <td>0.635942</td>\n",
              "      <td>4.067854</td>\n",
              "      <td>-0.688163</td>\n",
              "      <td>-0.871450</td>\n",
              "      <td>-0.914341</td>\n",
              "      <td>-0.667974</td>\n",
              "      <td>-0.386116</td>\n",
              "      <td>1.173936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.494716</td>\n",
              "      <td>0.348679</td>\n",
              "      <td>-0.514203</td>\n",
              "      <td>1.013379</td>\n",
              "      <td>1.515830</td>\n",
              "      <td>-0.510734</td>\n",
              "      <td>-0.829178</td>\n",
              "      <td>0.273282</td>\n",
              "      <td>-0.629810</td>\n",
              "      <td>-0.490601</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.85852</td>\n",
              "      <td>0.927870</td>\n",
              "      <td>-0.320838</td>\n",
              "      <td>-0.686965</td>\n",
              "      <td>1.308509</td>\n",
              "      <td>-0.871450</td>\n",
              "      <td>-0.914341</td>\n",
              "      <td>0.922712</td>\n",
              "      <td>-0.534845</td>\n",
              "      <td>0.233945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.684263</td>\n",
              "      <td>0.595475</td>\n",
              "      <td>-0.698777</td>\n",
              "      <td>0.084498</td>\n",
              "      <td>2.959814</td>\n",
              "      <td>-0.510734</td>\n",
              "      <td>-0.829178</td>\n",
              "      <td>-0.950473</td>\n",
              "      <td>-0.629810</td>\n",
              "      <td>-0.490601</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.85852</td>\n",
              "      <td>-0.771150</td>\n",
              "      <td>0.829837</td>\n",
              "      <td>-0.254614</td>\n",
              "      <td>-0.981759</td>\n",
              "      <td>-0.871450</td>\n",
              "      <td>2.534453</td>\n",
              "      <td>-0.667974</td>\n",
              "      <td>-0.534845</td>\n",
              "      <td>3.130798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.684263</td>\n",
              "      <td>-0.706851</td>\n",
              "      <td>-0.698777</td>\n",
              "      <td>1.511019</td>\n",
              "      <td>-0.210173</td>\n",
              "      <td>-0.510734</td>\n",
              "      <td>0.467025</td>\n",
              "      <td>-0.258887</td>\n",
              "      <td>1.199516</td>\n",
              "      <td>-0.157384</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.85852</td>\n",
              "      <td>0.983767</td>\n",
              "      <td>2.165945</td>\n",
              "      <td>1.594887</td>\n",
              "      <td>-0.981759</td>\n",
              "      <td>-0.871450</td>\n",
              "      <td>-0.914341</td>\n",
              "      <td>-0.667974</td>\n",
              "      <td>-0.534845</td>\n",
              "      <td>-0.791722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.684263</td>\n",
              "      <td>-0.706851</td>\n",
              "      <td>-0.698777</td>\n",
              "      <td>-0.312307</td>\n",
              "      <td>-0.771167</td>\n",
              "      <td>-0.510734</td>\n",
              "      <td>1.055458</td>\n",
              "      <td>-0.569919</td>\n",
              "      <td>-0.629810</td>\n",
              "      <td>-0.490601</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.85852</td>\n",
              "      <td>-0.458171</td>\n",
              "      <td>-0.771627</td>\n",
              "      <td>6.847553</td>\n",
              "      <td>-0.422549</td>\n",
              "      <td>0.932286</td>\n",
              "      <td>-0.914341</td>\n",
              "      <td>-0.667974</td>\n",
              "      <td>-0.135992</td>\n",
              "      <td>-0.791722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.684263</td>\n",
              "      <td>0.506747</td>\n",
              "      <td>3.384523</td>\n",
              "      <td>-0.832172</td>\n",
              "      <td>0.010346</td>\n",
              "      <td>0.925514</td>\n",
              "      <td>-0.829178</td>\n",
              "      <td>0.181350</td>\n",
              "      <td>-0.629810</td>\n",
              "      <td>-0.490601</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.85852</td>\n",
              "      <td>0.894464</td>\n",
              "      <td>3.494938</td>\n",
              "      <td>-0.686965</td>\n",
              "      <td>-0.981759</td>\n",
              "      <td>-0.871450</td>\n",
              "      <td>-0.017789</td>\n",
              "      <td>-0.039492</td>\n",
              "      <td>-0.534845</td>\n",
              "      <td>1.515929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.529879</td>\n",
              "      <td>-0.706851</td>\n",
              "      <td>1.716731</td>\n",
              "      <td>-0.622971</td>\n",
              "      <td>-0.668859</td>\n",
              "      <td>-0.227116</td>\n",
              "      <td>-0.829178</td>\n",
              "      <td>-0.950473</td>\n",
              "      <td>-0.629810</td>\n",
              "      <td>-0.490601</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.85852</td>\n",
              "      <td>-0.771150</td>\n",
              "      <td>-0.030263</td>\n",
              "      <td>-0.686965</td>\n",
              "      <td>-0.981759</td>\n",
              "      <td>-0.871450</td>\n",
              "      <td>1.668778</td>\n",
              "      <td>-0.667974</td>\n",
              "      <td>-0.534845</td>\n",
              "      <td>0.616387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.684263</td>\n",
              "      <td>-0.706851</td>\n",
              "      <td>-0.698777</td>\n",
              "      <td>-0.556059</td>\n",
              "      <td>1.354789</td>\n",
              "      <td>-0.132860</td>\n",
              "      <td>-0.829178</td>\n",
              "      <td>-0.950473</td>\n",
              "      <td>-0.629810</td>\n",
              "      <td>-0.490601</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.85852</td>\n",
              "      <td>0.405067</td>\n",
              "      <td>-0.771627</td>\n",
              "      <td>2.012566</td>\n",
              "      <td>-0.981759</td>\n",
              "      <td>0.581057</td>\n",
              "      <td>-0.914341</td>\n",
              "      <td>-0.667974</td>\n",
              "      <td>2.621031</td>\n",
              "      <td>0.713698</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows  2048 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b50819c0-06d6-4d0a-82c9-765b442ad053')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b50819c0-06d6-4d0a-82c9-765b442ad053 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b50819c0-06d6-4d0a-82c9-765b442ad053');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "test_f.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95oPourHZoIm"
      },
      "outputs": [],
      "source": [
        "test_f_labels = test_lab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m87lftbZZD6k"
      },
      "outputs": [],
      "source": [
        "xg_predictions = xg.predict(test_f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rZAdZ8zbNo3",
        "outputId": "446c1eb3-1d91-4c4c-b129-c588be00b1cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "xg_predictions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-1UfshZb3dW"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZBMwRkZbnmx",
        "outputId": "912a059c-ebf2-4a3a-8411-2ef3debeebc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.86\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(test_f_labels, xg_predictions)\n",
        "print('Accuracy: {:.2f}'.format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E59FerWs3Bt",
        "outputId": "ac8cd880-ed56-40a6-e86a-387a13b0b861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (3.3.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm) (0.40.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_R7c6m2zinJ"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n119Q5i3zlj2"
      },
      "outputs": [],
      "source": [
        "lgb_clf = lgb.LGBMClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "vAwXlJ8b0CKs",
        "outputId": "c47a5ef2-254c-43f5-ddb6-31b91d52b907"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "lgb_clf.fit(train_f, train_f_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFlvqIZV0zaq"
      },
      "outputs": [],
      "source": [
        "lgb_pred = lgb_clf.predict(test_f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKxZqtC71itC",
        "outputId": "209309c1-3f25-4d48-8499-16772f54b0ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.87\n"
          ]
        }
      ],
      "source": [
        "accuracy_lgb = accuracy_score(test_f_labels, lgb_pred)\n",
        "print('Accuracy: {:.2f}'.format(accuracy_lgb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUXZ10Kv13px"
      },
      "source": [
        "## Now, using CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMtLtYDe1n_a",
        "outputId": "48edb6c8-e49e-47b3-bbdd-fa1394fc78c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2-cp310-cp310-manylinux2014_x86_64.whl (98.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m98.6/98.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2022.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2\n"
          ]
        }
      ],
      "source": [
        "pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5kRWk7t1_11"
      },
      "outputs": [],
      "source": [
        "import catboost as cb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kEx4hOZ2FSc"
      },
      "outputs": [],
      "source": [
        "cb_clf = cb.CatBoostClassifier(iterations = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hgn-Va52O-y",
        "outputId": "d280da12-9b52-420f-b9ed-889829e632d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.5\n",
            "0:\tlearn: 1.5740483\ttotal: 24.6s\tremaining: 40m 33s\n",
            "1:\tlearn: 1.3185279\ttotal: 37.4s\tremaining: 30m 31s\n",
            "2:\tlearn: 1.1601424\ttotal: 49.7s\tremaining: 26m 46s\n",
            "3:\tlearn: 1.0209379\ttotal: 1m 2s\tremaining: 24m 50s\n",
            "4:\tlearn: 0.9284055\ttotal: 1m 14s\tremaining: 23m 36s\n",
            "5:\tlearn: 0.8547204\ttotal: 1m 26s\tremaining: 22m 41s\n",
            "6:\tlearn: 0.7945572\ttotal: 1m 39s\tremaining: 21m 59s\n",
            "7:\tlearn: 0.7490452\ttotal: 1m 51s\tremaining: 21m 22s\n",
            "8:\tlearn: 0.7216398\ttotal: 2m 5s\tremaining: 21m 8s\n",
            "9:\tlearn: 0.6867275\ttotal: 2m 17s\tremaining: 20m 41s\n",
            "10:\tlearn: 0.6608640\ttotal: 2m 30s\tremaining: 20m 16s\n",
            "11:\tlearn: 0.6401072\ttotal: 2m 42s\tremaining: 19m 53s\n",
            "12:\tlearn: 0.6183706\ttotal: 2m 56s\tremaining: 19m 38s\n",
            "13:\tlearn: 0.5981249\ttotal: 3m 8s\tremaining: 19m 17s\n",
            "14:\tlearn: 0.5808643\ttotal: 3m 20s\tremaining: 18m 56s\n",
            "15:\tlearn: 0.5652689\ttotal: 3m 32s\tremaining: 18m 37s\n",
            "16:\tlearn: 0.5539592\ttotal: 3m 45s\tremaining: 18m 19s\n",
            "17:\tlearn: 0.5446307\ttotal: 3m 57s\tremaining: 18m 2s\n",
            "18:\tlearn: 0.5321705\ttotal: 4m 10s\tremaining: 17m 46s\n",
            "19:\tlearn: 0.5204405\ttotal: 4m 22s\tremaining: 17m 29s\n",
            "20:\tlearn: 0.5092706\ttotal: 4m 34s\tremaining: 17m 13s\n",
            "21:\tlearn: 0.5004323\ttotal: 4m 47s\tremaining: 16m 58s\n",
            "22:\tlearn: 0.4881284\ttotal: 4m 59s\tremaining: 16m 43s\n",
            "23:\tlearn: 0.4717246\ttotal: 5m 12s\tremaining: 16m 28s\n",
            "24:\tlearn: 0.4635845\ttotal: 5m 24s\tremaining: 16m 14s\n",
            "25:\tlearn: 0.4575583\ttotal: 5m 36s\tremaining: 15m 59s\n",
            "26:\tlearn: 0.4499659\ttotal: 5m 49s\tremaining: 15m 44s\n",
            "27:\tlearn: 0.4420544\ttotal: 6m 2s\tremaining: 15m 32s\n",
            "28:\tlearn: 0.4334214\ttotal: 6m 14s\tremaining: 15m 18s\n",
            "29:\tlearn: 0.4263959\ttotal: 6m 27s\tremaining: 15m 3s\n",
            "30:\tlearn: 0.4195279\ttotal: 6m 39s\tremaining: 14m 49s\n",
            "31:\tlearn: 0.4160193\ttotal: 6m 51s\tremaining: 14m 35s\n",
            "32:\tlearn: 0.4100979\ttotal: 7m 3s\tremaining: 14m 20s\n",
            "33:\tlearn: 0.4058663\ttotal: 7m 16s\tremaining: 14m 6s\n",
            "34:\tlearn: 0.4030279\ttotal: 7m 28s\tremaining: 13m 52s\n",
            "35:\tlearn: 0.3997322\ttotal: 7m 40s\tremaining: 13m 38s\n",
            "36:\tlearn: 0.3961899\ttotal: 7m 52s\tremaining: 13m 24s\n",
            "37:\tlearn: 0.3934236\ttotal: 8m 4s\tremaining: 13m 10s\n",
            "38:\tlearn: 0.3894369\ttotal: 8m 16s\tremaining: 12m 56s\n",
            "39:\tlearn: 0.3864650\ttotal: 8m 28s\tremaining: 12m 42s\n",
            "40:\tlearn: 0.3822378\ttotal: 8m 40s\tremaining: 12m 28s\n",
            "41:\tlearn: 0.3771881\ttotal: 8m 52s\tremaining: 12m 15s\n",
            "42:\tlearn: 0.3695099\ttotal: 9m 4s\tremaining: 12m 2s\n",
            "43:\tlearn: 0.3672755\ttotal: 9m 18s\tremaining: 11m 50s\n",
            "44:\tlearn: 0.3648385\ttotal: 9m 30s\tremaining: 11m 37s\n",
            "45:\tlearn: 0.3631631\ttotal: 9m 42s\tremaining: 11m 24s\n",
            "46:\tlearn: 0.3611762\ttotal: 9m 54s\tremaining: 11m 10s\n",
            "47:\tlearn: 0.3586696\ttotal: 10m 6s\tremaining: 10m 57s\n",
            "48:\tlearn: 0.3572355\ttotal: 10m 18s\tremaining: 10m 44s\n",
            "49:\tlearn: 0.3556699\ttotal: 10m 31s\tremaining: 10m 31s\n",
            "50:\tlearn: 0.3526090\ttotal: 10m 43s\tremaining: 10m 18s\n",
            "51:\tlearn: 0.3504488\ttotal: 10m 55s\tremaining: 10m 5s\n",
            "52:\tlearn: 0.3486677\ttotal: 11m 8s\tremaining: 9m 52s\n",
            "53:\tlearn: 0.3472500\ttotal: 11m 20s\tremaining: 9m 39s\n",
            "54:\tlearn: 0.3459198\ttotal: 11m 32s\tremaining: 9m 26s\n",
            "55:\tlearn: 0.3449622\ttotal: 11m 44s\tremaining: 9m 13s\n",
            "56:\tlearn: 0.3427682\ttotal: 11m 56s\tremaining: 9m\n",
            "57:\tlearn: 0.3408588\ttotal: 12m 9s\tremaining: 8m 47s\n",
            "58:\tlearn: 0.3386686\ttotal: 12m 21s\tremaining: 8m 35s\n",
            "59:\tlearn: 0.3379340\ttotal: 12m 34s\tremaining: 8m 23s\n",
            "60:\tlearn: 0.3366576\ttotal: 12m 46s\tremaining: 8m 10s\n",
            "61:\tlearn: 0.3357044\ttotal: 12m 59s\tremaining: 7m 57s\n",
            "62:\tlearn: 0.3346761\ttotal: 13m 11s\tremaining: 7m 44s\n",
            "63:\tlearn: 0.3332686\ttotal: 13m 23s\tremaining: 7m 32s\n",
            "64:\tlearn: 0.3315229\ttotal: 13m 35s\tremaining: 7m 19s\n",
            "65:\tlearn: 0.3304392\ttotal: 13m 48s\tremaining: 7m 6s\n",
            "66:\tlearn: 0.3293217\ttotal: 14m\tremaining: 6m 53s\n",
            "67:\tlearn: 0.3268979\ttotal: 14m 12s\tremaining: 6m 41s\n",
            "68:\tlearn: 0.3252052\ttotal: 14m 24s\tremaining: 6m 28s\n",
            "69:\tlearn: 0.3240471\ttotal: 14m 37s\tremaining: 6m 15s\n",
            "70:\tlearn: 0.3230525\ttotal: 14m 49s\tremaining: 6m 3s\n",
            "71:\tlearn: 0.3217289\ttotal: 15m 1s\tremaining: 5m 50s\n",
            "72:\tlearn: 0.3200936\ttotal: 15m 13s\tremaining: 5m 37s\n",
            "73:\tlearn: 0.3193751\ttotal: 15m 25s\tremaining: 5m 25s\n",
            "74:\tlearn: 0.3179869\ttotal: 15m 39s\tremaining: 5m 13s\n",
            "75:\tlearn: 0.3159284\ttotal: 15m 51s\tremaining: 5m\n",
            "76:\tlearn: 0.3153106\ttotal: 16m 4s\tremaining: 4m 48s\n",
            "77:\tlearn: 0.3139123\ttotal: 16m 16s\tremaining: 4m 35s\n",
            "78:\tlearn: 0.3124956\ttotal: 16m 28s\tremaining: 4m 22s\n",
            "79:\tlearn: 0.3111919\ttotal: 16m 41s\tremaining: 4m 10s\n",
            "80:\tlearn: 0.3103311\ttotal: 16m 54s\tremaining: 3m 57s\n",
            "81:\tlearn: 0.3092268\ttotal: 17m 7s\tremaining: 3m 45s\n",
            "82:\tlearn: 0.3082474\ttotal: 17m 19s\tremaining: 3m 32s\n",
            "83:\tlearn: 0.3072819\ttotal: 17m 31s\tremaining: 3m 20s\n",
            "84:\tlearn: 0.3063428\ttotal: 17m 43s\tremaining: 3m 7s\n",
            "85:\tlearn: 0.3054170\ttotal: 17m 55s\tremaining: 2m 55s\n",
            "86:\tlearn: 0.3038827\ttotal: 18m 7s\tremaining: 2m 42s\n",
            "87:\tlearn: 0.3017747\ttotal: 18m 20s\tremaining: 2m 30s\n",
            "88:\tlearn: 0.3006106\ttotal: 18m 32s\tremaining: 2m 17s\n",
            "89:\tlearn: 0.3001525\ttotal: 18m 44s\tremaining: 2m 4s\n",
            "90:\tlearn: 0.2990032\ttotal: 18m 58s\tremaining: 1m 52s\n",
            "91:\tlearn: 0.2980746\ttotal: 19m 10s\tremaining: 1m 40s\n",
            "92:\tlearn: 0.2968280\ttotal: 19m 22s\tremaining: 1m 27s\n",
            "93:\tlearn: 0.2959363\ttotal: 19m 34s\tremaining: 1m 14s\n",
            "94:\tlearn: 0.2945342\ttotal: 19m 47s\tremaining: 1m 2s\n",
            "95:\tlearn: 0.2940124\ttotal: 19m 59s\tremaining: 50s\n",
            "96:\tlearn: 0.2925346\ttotal: 20m 12s\tremaining: 37.5s\n",
            "97:\tlearn: 0.2914042\ttotal: 20m 24s\tremaining: 25s\n",
            "98:\tlearn: 0.2904692\ttotal: 20m 36s\tremaining: 12.5s\n",
            "99:\tlearn: 0.2895093\ttotal: 20m 48s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f978845a590>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "cb_clf.fit(train_f, train_f_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgVwxkbM2U9w"
      },
      "outputs": [],
      "source": [
        "clf_pred = cb_clf.predict(test_f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wZBPI3r3DYq",
        "outputId": "14fc8290-0405-40c9-a456-813d335700bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.84\n"
          ]
        }
      ],
      "source": [
        "accuracy_clf = accuracy_score(test_f_labels, clf_pred)\n",
        "print('Accuracy: {:.2f}'.format(accuracy_clf))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cQ9iHxcCCYFH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}